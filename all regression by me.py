# -*- coding: utf-8 -*-
"""Untitled0.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1RoHzdAKCpB7SccGF59vv492ZzSEJJucp

practical of the regression

1 data ingestion
2 eda
3 preprocessing or fe
4 model
5 evaluation
"""

import pandas as pd

df=pd.read_csv("/placement.csv")

df.head()

import matplotlib.pyplot as plt
plt.scatter(df["cgpa"],df["placement_exam_marks"])
plt.xlabel("cgpa")
plt.ylabel("placement_exam_marks")

df.iloc[:,0:1]

df.iloc[:,-1]

X=df.iloc[:,0:1]
Y=df.iloc[:,-1]

df.shape

1000*0.15

from sklearn.model_selection import train_test_split

"""#random smapling it might anything my 1 also

"""

X_train,X_test,Y_train,y_test=train_test_split(X,Y,test_size=0.15,random_state=42)

X_train.shape

X_test.shape

from sklearn .linear_model import LinearRegression

model=LinearRegression()

model.fit(X_train,Y_train)

model.score(X_train,X_train)

"""low bias
plt.threading0.9

high variance
testing
0.5

#i can use regulaztion technique

0-1
if we are getting are r2 value near to 1 that model will best model
"""

X_test

#THIS WAS MY BULK PREDICTIONS
y_pred=model.predict(X_test)

y_test

from sklearn.metrics import r2_score

r2_score(y_test, y_pred)

model.coef_

model.intercept_

y=0.55*0.911

y=0.55*(7.8)-0.911

y

model.predict([[9.6]])

plt.scatter(df["cgpa"],df["placement_exam_marks"])
plt.plot(X_train,model.predict(X_train),color="red")

#multiple lnear regression

from sklearn.datasets import make_regression
X,y=make_regression(n_samples=150,n_features=2,n_targets=1,noise=40)

y

X

df=pd.Dataframe({'feature1':X[:,0],'feature2':X[:,1],'target':y})

df.head()

df.shape

import plotly.express as px
px.scatter_3d(df,x="cgpa",y="placement_exam_marks",z="placed")

from sklearn.model_selection import train_test_split
 X_train,X_test,Y_train,y_test=train_test_split(X,Y,test_size=0.2,random_state=3)

X_train.shape

model2=LinearRegression()

model2.fit(X_train,Y_train)

model2.score(X_train,Y_train)

model2.predict(X_test)



y_pred2=model2.predict(X_test)

r2_score(y_test,y_pred2)

model2.coef_

model2.intercept_

y=m1*1+m2*2+c

y=theta*1+theta2*2+c

y=83.6(*1)+89.76(*2)-3.56

y_test this i my actual value
y_pd this is predicted value

from sklearn.metrics import mean_absolute_error,mean_squared_error

mean_squared_error(y_test,y_pred2)

mean_absolute_error(y_test,y_pred2)

from sklearn.datasets import load_diabetes

data=load_diabetes()

print(data.DESCR)

X=data.data

X

y=data.target

y

from sklearn.model_selection import train_test_split

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=3)

X_train

y_train

model3=LinearRegression()

model3.fit(X_train,y_train)

model3.score(X_train,y_train)

#for training the score is 0.51

y_pred3=model3.predict(X_test)

r2_score(y_test,y_pred3)

#for training the score is 0.518

from sklearn . linear_model import Ridge

model4=Ridge()

model4.fit(X_train,y_train)

model4.score(X_train,y_train)

model4.predict(X_test)

y_pred4=model4.predict(X_test)

r2_score(y_test,y_pred4)

model5=Ridge(alpha=100)

model5.fit(X_train,y_train)

model5.score(X_train,y_train)

y_pred5=model5.predict(X_test)

r2_score(y_test,y_pred5)

model5.coef_

model5.intercept_

pip install sklearn.liner_model

X,y=make_regression(n_samples=200,n_features=1,n_informative=1,n_targets=1,noise=40,random_state=13)

X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2)

plt.scatter(X,y)

from sklearn.linear_model import LinearRegression

reg=LinearRegression()
reg.fit(X_train,y_train)
print(reg.coef_)
print(reg.intercept_)

X

y

reg.score(X_train,y_train)

pred=reg.predict(X_test)

r2_score(y_test,pred)

from sklearn .linear_model import Lasso

model7=Lasso()

model7.fit(X_train,y_train)
score=model.score(X_train,y_train)
print(score)
pred=model7.predict(X_test)
r2_score(y_test,pred)







"""# New Section

# New Section
"""